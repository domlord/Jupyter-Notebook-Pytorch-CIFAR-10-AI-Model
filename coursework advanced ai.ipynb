{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa13495b-9de1-42a5-9bbd-82e2ef0f92dc",
   "metadata": {},
   "source": [
    "How to train a neural network to classify images using the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a478a-6ac6-4c21-891d-2d3fe3c060bb",
   "metadata": {},
   "source": [
    "TABLE OF CONTENTS:\n",
    "1. Introduction\n",
    "2. Dataset and Libraries\n",
    "3. Data Preprocessing and Visualisation\n",
    "4. Model Definition and Training\n",
    "5. Hyperparameter Tuning\n",
    "6. Evaluation and Results\n",
    "7. Conclusion\n",
    "8. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4288d0d-9b12-461b-9db1-a4828c988923",
   "metadata": {},
   "source": [
    "ABSTRACT:\n",
    "This tutorial demonstrates how to use Jupyter Notebook to develop a machine learning pipeline for image classification using PyTorch. \n",
    "This tutorial will utilise the CIFAR-10 dataset, which consists of 10 different object categories. \n",
    "The topics covers within include: data preprocessing, model training, evaluation, and hyperparameter tuning.\n",
    "By the end of this guide, users will have a fully functional AI system capable of classifying images \n",
    "and understanding how different hyperparameters affect model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22071c82-91c4-49d2-bdd0-576e2249b728",
   "metadata": {},
   "source": [
    "To begin, it is important to ensure that our machine learning pipeline is able to access all appropriate libraries. To achieve this, we can import that which we require. For this tutorial, we will use the libraries Pytorch, Matplotlib and Numpy. As such, we will import them as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec1a3c3-51d1-45ea-ba4b-95b1a4e75355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# PyTorch Library: PyTorch Team. (2025). torch module documentation. Retrieved February 25, 2025, from https://pytorch.org/docs/stable/index.html\n",
    "# Torchvision: PyTorch Team. (2025). torchvision module documentation. Retrieved February 25, 2025, from https://pytorch.org/vision/stable/index.html\n",
    "# Matplotlib: Hunter, J. D. (2007). Matplotlib: A 2D Graphics Environment. Computing in Science & Engineering, 9(3), 90-95. Retrieved February 25, 2025, from https://matplotlib.org/stable/index.html\n",
    "# NumPy: Harris, C. R., et al. (2020). Array programming with NumPy. Nature, 585(7825), 357â€“362. Retrieved February 25, 2025, from https://numpy.org/doc/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c742371-d974-4ab4-bf34-3775beeefe11",
   "metadata": {},
   "source": [
    "Following the importing of the required libraries, it is important to give our model the ability to train on an accelerator. An accelerator is a\n",
    "device that can be used alongside the CPU to speed up the computation of our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e7236b-27b0-4301-a624-244a82024b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "# [Source: https://pytorch.org/docs/stable/notes/cuda.html]\n",
    "# https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#model-layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df457ba-7b74-43e5-a292-b6f62adedcce",
   "metadata": {},
   "source": [
    "The next stage of the machine learning pipeline is the loading of normalisation of the data that is to be used to train the model.\n",
    "This data will be ingested by the pipeline, and will be used to teach the pipeline how to separate the data into appropriate groups.\n",
    "In this example, we will be using image data from the CIFAR10. The pipeline will then use these images and their classifications to learn which\n",
    "attributes are present in each group, and will gain the ability to identify which images belong in each group based on these attributes.\n",
    "We will be modifying the data such that it is appropriate for utility within our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec392a31-8ddc-484c-bf12-4f2c934075ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load and Normalise Data\n",
    "# Download and dataloader data from the CIFAR10 as shown in https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# We use transforms to change attributes of the data to make it appropriate for the pipeline.\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flips images horizontally to introduce variation\n",
    "    transforms.RandomRotation(10),  # Rotates images by a small angle to enhance model robustness\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjusts brightness/contrast\n",
    "    transforms.ToTensor(),  # Converts images to tensors for PyTorch compatibility\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizes pixel values to improve learning stability\n",
    "])\n",
    "# Loading CIFAR-10 dataset [Source: https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.CIFAR10]\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=data_transform, download=True)\n",
    "\n",
    "# DataLoader allows efficient batch loading [Source: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader]\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# PyTorch Team. (2025). torch.cuda documentation. Retrieved February 25, 2025, from https://pytorch.org/docs/stable/cuda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f37763-50d5-4752-a857-af51f74ca402",
   "metadata": {},
   "source": [
    "Next, we will define the Convolutional Neural Network to be used in our machine learning pipeline.\n",
    "As we are training our pipeline to be able to identify image data, a CNN is most approrpiate. This is due to the fact that CNNs are able to \n",
    "automatically capture spatial hierarchies in images, including that of edges and textures. CNNs will also be able to identify any more patterns that \n",
    "occur within the data set.\n",
    "Within this neural network, we will use multiple convolutional layers, batch normalisation, ReLU and pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92885225-9369-47a3-be6b-bd749530ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define CNN Model with Batch Normalisation and Dropout\n",
    "class CNN(nn.Module):  # [Source: PyTorch Official Examples]\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer extracts low-level features [Source: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html]\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Increased Filters\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Second convolutional layer extracts mid-level features.\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Third convolutional layer extracts deeper patterns.\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # Added Extra Layer\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Max pooling reduces spatial dimensions while retaining important features. [Source: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Dropout prevents overfitting [Source: https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html]\n",
    "        self.dropout = nn.Dropout(0.4)  # Adjusted Dropout\n",
    "\n",
    "        # Fully connected layers for classification.\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 256)  # Adjusted Fully Connected Layer\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    # Define the forward pass of the neural network\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x)))) # Apply first convolution and ReLU activation\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x)))) # Apply second convolution and ReLU activation\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x)))) # Apply third convolution and ReLU activation\n",
    "        x = torch.flatten(x, 1) # Flattens feature maps into a vector for FC layers [Source: https://pytorch.org/docs/stable/generated/torch.flatten.html]\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x) # Applies dropout for regularisation [Source: https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html]\n",
    "        x = self.fc2(x) # Final classification layer [Source: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html]\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model and move it to the selected device.\n",
    "model = CNN().to(device)\n",
    "\n",
    "# https://medium.com/@myringoleMLGOD/simple-convolutional-neural-network-cnn-for-dummies-in-pytorch-a-step-by-step-guide-6f4109f6df80\n",
    "# PyTorch Team. (2025). torchvision.transforms documentation. Retrieved February 25, 2025, from https://pytorch.org/vision/stable/transforms.html\n",
    "# Normalisation values for CIFAR-10: Krizhevsky, A. (2009). Learning Multiple Layers of Features from Tiny Images. University of Toronto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a278-e560-42a9-8746-c05dce2015d9",
   "metadata": {},
   "source": [
    "The next stage of the machine learning pipeline is to use the torch.optim package to implement different optimisation algorithms.\n",
    "Within this tutorial, I will be using the cross entropy loss, stochastic gradient descent and cosine annealing learning rate enhancements.\n",
    "Each of these optimisation algorithms can be used to increase the accuracy of the model produced.\n",
    "The loss function used is CrossEntropyLoss, commonly used for multi-class classification problems. We will use it within our pipeline to quantify how far the predicted values are from the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0ea0aa-567b-4381-aea1-efb28c444c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Loss, Optimiser, and Scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Cross-entropy loss for multi-class classification\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)  # Stochastic Gradient Descent with momentum \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)  # Cosine Annealing Learning Rate \n",
    "\n",
    "# [Source: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html]\n",
    "# [Source: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html]\n",
    "# [Source: https://pytorch.org/docs/stable/generated/torch.optim.SGD.html]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332ef98-4f71-4dd4-bc36-110403793914",
   "metadata": {},
   "source": [
    "The next stage of the machine learning pipeline is to feed the data present in the dataset into our model. One way that we can alter the accuracy of the model is by changing the number of epochs that our model is trained using. Each epoch is an iteration of the entire training dataset. As such, increasing the number of epochs used to train our model will increase the ability of our model to identify the data in the data set. However, it is important to not make the number of epochs used too large, as it can lead to overfitting, which is the occurance of an AI only being able to accurately predict the training data, and innacurately deals with the validation and testing data.\n",
    "Within the training loop we will include the functionality of calculating and demonstrating the accuracy of the model both as text and graphically through the use of the Matplotlib library.\n",
    "This training loop uses backpropagation and an optimiser to teach the AI, allowing for increased performance and predictive ability.\n",
    "We calculate the loss of the model in two different modes, that of the training mode and the evaluation mode. This is done to test the model under separate conditions, testing how well the model deals with both seen and unseen data. This is done to measure if the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b990097-4312-4a58-8748-a15c15802519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 1.3726, Train Acc: 50.15% | Val Loss: 1.0860, Val Acc: 60.70%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Training Loop\n",
    "def train_model(model, train_loader, test_loader, criterion, optimiser, scheduler, num_epochs=15):\n",
    "    model.train()\n",
    "    train_losses, val_losses = [], [] # Arrays used to store losses \n",
    "    train_accuracies, val_accuracies = [], [] # Arrays used to store calculated accuracies\n",
    "    epochs = []\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss, correct_train, total_train = 0.0, 0, 0 # Values that store the number of \n",
    "        for images, labels in train_loader: # For each image and classification within the set of training data\n",
    "            images, labels = images.to(device), labels.to(device) #Send the input to the device\n",
    "            optimiser.zero_grad() # Sets the grads to zero, increasing performance\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) # Calculates how far the predicted values are from the true labels\n",
    "            loss.backward() # Backpropagation to compute gradients \n",
    "            optimiser.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        epochs.append(epoch + 1)\n",
    "        \n",
    "        model.eval() # Sets the model to evaluation mode for validation\n",
    "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad(): # Disable gradient computation for validation\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) # Compute validation loss\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(test_loader)\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        scheduler.step() # Adjust learning rate\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        model.train() # Switch back to training mode\n",
    "        \n",
    "    # Plot Training Results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
    "\n",
    "train_model(model, train_loader, test_loader, criterion, optimiser, scheduler, num_epochs=15) # Run the model\n",
    "# https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
    "# https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "# https://pytorch.org/docs/stable/autograd.html\n",
    "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html\n",
    "# https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n",
    "# https://pytorch.org/docs/stable/generated/torch.max.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5f367-93c7-4dc1-a00b-8be172310377",
   "metadata": {},
   "outputs": [],
   "source": [
    "After training the AI model, we can use the model to classify images that are present within the training set.\n",
    "The following code graphs an image, along with the group that the model identifies it to fit within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b9a90-bc65-472e-b334-ea0015eb9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualising Predictions\n",
    "def visualise_predictions(model, test_loader):\n",
    "    classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    model.eval()\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "    for i in range(9):\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        img = (img * 0.5) + 0.5  # Unnormalise\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'True: {classes[labels[i]]}\\nPred: {classes[preds[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualise_predictions(model, test_loader)  # Call visualisation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cfa4c-7d8e-4917-9860-e2a2ac57322c",
   "metadata": {},
   "source": [
    "To make the predictions more accurate, we can change the number of epochs, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6905dd-b8fd-4639-9fec-36de25b0011b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe04213-974e-47d1-b0e6-80d7ce466edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
